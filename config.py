#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç”Ÿç”£ç‰ˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ« - ç’°å¢ƒå¤‰æ•°å¯¾å¿œ
Environment-based configuration for production use
"""

import os
import logging
import yaml
from pathlib import Path
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Load YAML configuration
def load_yaml_config():
    """Load configuration from config.yaml if it exists"""
    config_path = Path(__file__).parent / "config.yaml"
    if config_path.exists():
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f) or {}
        except Exception as e:
            print(f"Warning: Failed to load config.yaml: {e}")
    return {}

_yaml_config = load_yaml_config()

# Streamlit import for secrets management
try:
    import streamlit as st
    STREAMLIT_AVAILABLE = True
except ImportError:
    STREAMLIT_AVAILABLE = False

class Config:
    """Production configuration class with environment variable support"""
    
    # ==================================================
    # Base Directory Configuration
    # ==================================================
    BASE_DIR = Path(os.getenv('BASE_DIR', Path(__file__).parent))
    
    # ==================================================
    # Directory Path Settings
    # ==================================================
    INPUT_DIR = Path(os.getenv('INPUT_DIR', BASE_DIR / "input_all"))
    OUTPUT_DIR = Path(os.getenv('OUTPUT_DIR', BASE_DIR / "output"))
    TEMP_DIR = Path(os.getenv('TEMP_DIR', BASE_DIR / "temp"))
    LOG_DIR = Path(os.getenv('LOG_DIR', BASE_DIR / "logs"))
    
    # Create directories if they don't exist
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    TEMP_DIR.mkdir(parents=True, exist_ok=True) 
    LOG_DIR.mkdir(parents=True, exist_ok=True)
    
    # ==================================================
    # File Name Settings
    # ==================================================
    OUTPUT_CSV_NAME = os.getenv('OUTPUT_CSV_NAME', "extracted_journal_entries_mjs45.csv")
    OUTPUT_CSV_PATH = OUTPUT_DIR / OUTPUT_CSV_NAME
    LOG_FILE_NAME = os.getenv('LOG_FILE_NAME', "pdf_extraction.log")
    LOG_FILE_PATH = LOG_DIR / LOG_FILE_NAME
    
    # ==================================================
    # Account Code CSV Path
    # ==================================================
    ACCOUNT_CODE_CSV_PATH = os.getenv('ACCOUNT_CODE_CSV_PATH', BASE_DIR / "å‹˜å®šç§‘ç›®ã‚³ãƒ¼ãƒ‰ä¸€è¦§.csv")
    
    # ==================================================
    # API Configuration
    # ==================================================
    
    # Anthropic Claude API (Claude Sonnet 4.0) - ãƒ¡ã‚¤ãƒ³API
    @classmethod
    def _get_secret(cls, key: str, default: str = None) -> str:
        """Get secret from Streamlit secrets, TOML file, or environment variables"""
        # First try Streamlit secrets if available
        if STREAMLIT_AVAILABLE:
            try:
                return st.secrets.get(key, os.getenv(key, default))
            except:
                pass
        
        # Try loading from .streamlit/secrets.toml directly
        try:
            import toml
            secrets_path = Path(__file__).parent / ".streamlit" / "secrets.toml"
            if secrets_path.exists():
                secrets_data = toml.load(secrets_path)
                if key in secrets_data:
                    return secrets_data[key]
        except Exception:
            pass
        
        # Fallback to environment variables
        return os.getenv(key, default)
    
    @property
    def ANTHROPIC_API_KEY(self) -> str:
        return self._get_secret('ANTHROPIC_API_KEY')
    
    @property 
    def GOOGLE_API_KEY(self) -> str:
        """Get Google API key from Streamlit secrets or environment variables"""
        return self._get_secret('GOOGLE_API_KEY')
    
    ANTHROPIC_MODEL = os.getenv('ANTHROPIC_MODEL', 'claude-sonnet-4-20250514')
    ANTHROPIC_MAX_TOKENS = int(os.getenv('ANTHROPIC_MAX_TOKENS', '64000'))  # Claudeæœ€é©åŒ–: å¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†å¯¾å¿œ
    ANTHROPIC_BETA_HEADERS = os.getenv('ANTHROPIC_BETA_HEADERS', 'context-1m-2025-08-07')  # ä¿®æ­£: ä¸æ­£ãªæ—¥ä»˜å½¢å¼ã‚’ä¿®æ­£
    
    # OCR.space API
    OCR_SPACE_API_KEY = os.getenv('OCR_SPACE_API_KEY')
    OCR_SPACE_ENDPOINT = os.getenv('OCR_SPACE_ENDPOINT', 'https://api.ocr.space/parse/image')
    
    # Azure Document Intelligence
    AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT = os.getenv('AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT')
    AZURE_DOCUMENT_INTELLIGENCE_KEY = os.getenv('AZURE_DOCUMENT_INTELLIGENCE_KEY')
    
    # Google Document AI
    GOOGLE_APPLICATION_CREDENTIALS = os.getenv('GOOGLE_APPLICATION_CREDENTIALS')
    GOOGLE_PROJECT_ID = os.getenv('GOOGLE_PROJECT_ID')
    
    # ==================================================
    # Processing Settings
    # ==================================================
    USE_MOCK_DATA = False  # ãƒ¢ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰å®Œå…¨æ’¤å»ƒ - å¸¸ã«æœ¬ç•ªAPIä½¿ç”¨
    DEBUG_MODE = os.getenv('DEBUG_MODE', 'false').lower() == 'true'
    
    # PDF Processing
    # ç’°å¢ƒå¤‰æ•°ã‚ˆã‚Šå„ªå…ˆ: config.yamlã¾ãŸã¯ã‚³ãƒ¼ãƒ‰å†…ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨
    PAGES_PER_SPLIT = _yaml_config.get('pdf', {}).get('pages_per_split', 7)  # Claudeæœ€é©åŒ–: ãƒãƒ©ãƒ³ã‚¹å‹ï¼ˆAPIå‘¼ã³å‡ºã—å›æ•°ã¨ç”»åƒã‚µã‚¤ã‚ºã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ï¼‰
    MAX_FILE_SIZE_MB = int(os.getenv('MAX_FILE_SIZE_MB', '50'))
    PDF_DPI = _yaml_config.get('pdf', {}).get('dpi', 150)  # Claudeæœ€é©åŒ–: 150DPIï¼ˆå“è³ªã¨ã‚³ã‚¹ãƒˆã®ãƒãƒ©ãƒ³ã‚¹ï¼‰
    
    # Right column zoom for credit side improvement
    RIGHT_COL_ZOOM = _yaml_config.get('pdf', {}).get('right_col_zoom', False)
    RIGHT_COL_DPI = int(_yaml_config.get('pdf', {}).get('dpi', PDF_DPI))  # Use same DPI or config override

    # Voucher numbering settings
    USE_LLM_VOUCHER_NO = _yaml_config.get('processing', {}).get('use_llm_voucher_no', False)  # è²¸å€Ÿä¸€è‡´ãƒ–ãƒ­ãƒƒã‚¯æ–¹å¼ã‚’å„ªå…ˆ
    VOUCHER_NO_WIDTH = int(_yaml_config.get('processing', {}).get('voucher_no_width', 4))  # 4æ¡0001-9999å½¢å¼
    
    # API Rate Limiting
    API_REQUEST_INTERVAL = 0.5  # Claudeæœ€é©åŒ–: ä¸¦åˆ—å‡¦ç†å‰æã§çŸ­ç¸®ï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ï¼‰
    MAX_RETRIES = int(os.getenv('MAX_RETRIES', '1'))  # 1å›ãƒªãƒˆãƒ©ã‚¤ã®ã¿
    REQUEST_TIMEOUT = 180  # Claudeæœ€é©åŒ–: 180ç§’ï¼ˆ7ãƒšãƒ¼ã‚¸å‡¦ç†ã«ååˆ†ï¼‰
    
    # OCR Settings
    OCR_LANGUAGES = os.getenv('OCR_LANGUAGES', 'jpn+eng')
    OCR_ENGINE = os.getenv('OCR_ENGINE', 'auto')
    
    # ==================================================
    # Logging Configuration
    # ==================================================
    LOG_LEVEL = os.getenv('LOG_LEVEL', 'INFO')
    LOG_FORMAT = os.getenv('LOG_FORMAT', '%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    LOG_MAX_BYTES = int(os.getenv('LOG_MAX_BYTES', '10485760'))  # 10MB
    LOG_BACKUP_COUNT = int(os.getenv('LOG_BACKUP_COUNT', '5'))
    MASK_API_KEYS_IN_LOGS = os.getenv('MASK_API_KEYS_IN_LOGS', 'true').lower() == 'true'
    
    # ==================================================
    # Production Safety Settings
    # ==================================================
    VALIDATE_INPUT_FILES = os.getenv('VALIDATE_INPUT_FILES', 'true').lower() == 'true'
    BACKUP_ORIGINAL_FILES = os.getenv('BACKUP_ORIGINAL_FILES', 'true').lower() == 'true'
    CLEANUP_TEMP_FILES = os.getenv('CLEANUP_TEMP_FILES', 'true').lower() == 'true'
    ENCRYPT_TEMP_FILES = os.getenv('ENCRYPT_TEMP_FILES', 'false').lower() == 'true'
    
    # ==================================================
    # Performance Settings
    # ==================================================
    MAX_CONCURRENT_REQUESTS = 1  # ã‚·ãƒ¼ã‚±ãƒ³ã‚·ãƒ£ãƒ«å‡¦ç†ï¼ˆStreamlitç’°å¢ƒã§ã®ãƒ¡ãƒ¢ãƒªåˆ¶ç´„è€ƒæ…®ï¼‰
    WORKER_POOL_SIZE = int(os.getenv('WORKER_POOL_SIZE', '4'))
    MAX_MEMORY_MB = int(os.getenv('MAX_MEMORY_MB', '2048'))
    GARBAGE_COLLECTION_INTERVAL = int(os.getenv('GARBAGE_COLLECTION_INTERVAL', '100'))
    
    # ==================================================
    # Business Logic Settings
    # ==================================================
    VALIDATE_AMOUNTS = os.getenv('VALIDATE_AMOUNTS', 'true').lower() == 'true'
    MIN_AMOUNT = float(os.getenv('MIN_AMOUNT', '1'))
    MAX_AMOUNT = float(os.getenv('MAX_AMOUNT', '10000000'))
    
    REQUIRED_DATE_FORMAT = os.getenv('REQUIRED_DATE_FORMAT', 'R%y/%m/%d')
    VALIDATE_ACCOUNT_NAMES = os.getenv('VALIDATE_ACCOUNT_NAMES', 'true').lower() == 'true'
    
    # ==================================================
    # Post-Processing Settings
    # ==================================================
    class POSTPROCESS:
        SUM_TOLERANCE = int(os.getenv('POSTPROCESS_SUM_TOLERANCE', '0'))
        DROP_BOTH_CODE_EMPTY = os.getenv('POSTPROCESS_DROP_BOTH_CODE_EMPTY', 'true').lower() == 'true'
    
    # ==================================================
    # Error Handling
    # ==================================================
    ENABLE_RETRY = os.getenv('ENABLE_RETRY', 'true').lower() == 'true'  # 1å›ãƒªãƒˆãƒ©ã‚¤æœ‰åŠ¹
    RETRY_DELAY = float(os.getenv('RETRY_DELAY', '5'))
    EXPONENTIAL_BACKOFF = os.getenv('EXPONENTIAL_BACKOFF', 'false').lower() == 'true'
    
    SEND_ERROR_REPORTS = os.getenv('SEND_ERROR_REPORTS', 'false').lower() == 'true'
    ERROR_REPORT_EMAIL = os.getenv('ERROR_REPORT_EMAIL')
    
    # ==================================================
    # Development Settings
    # ==================================================
    DEVELOPMENT_MODE = os.getenv('DEVELOPMENT_MODE', 'false').lower() == 'true'
    RUN_UNIT_TESTS = os.getenv('RUN_UNIT_TESTS', 'false').lower() == 'true'
    GENERATE_TEST_REPORTS = os.getenv('GENERATE_TEST_REPORTS', 'false').lower() == 'true'
    
    # ==================================================
    # API Pricing Configuration (USD per 1K tokens)
    # ==================================================
    API_PRICES = {
        # OpenAI GPT-5 (Latest)
        "gpt-5": {"input": 0.005, "output": 0.015},
        "gpt-5-mini": {"input": 0.001, "output": 0.003},
        # Anthropic Claude (Latest)
        "claude-sonnet-4-20250514": {"input": 0.003, "output": 0.015},
        "claude-3-5-sonnet": {"input": 0.003, "output": 0.015},  # Legacy
        # Google Gemini (Latest)
        "gemini-2.5-flash": {"input": 0.0003, "output": 0.0006},
        "gemini-2.5-pro": {"input": 0.0015, "output": 0.005},
        "gemini-1.5-pro": {"input": 0.0015, "output": 0.005},  # Legacy
        "gemini-1.5-flash": {"input": 0.0003, "output": 0.0006},  # Legacy
    }
    
    # USD to JPY conversion rate (approximate)
    USD_TO_JPY_RATE = float(os.getenv('USD_TO_JPY_RATE', '150'))
    
    @classmethod
    def get_current_usd_to_jpy_rate(cls) -> float:
        """
        ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ USD-JPYç‚ºæ›¿ãƒ¬ãƒ¼ãƒˆã‚’å–å¾—
        è¤‡æ•°ã®APIã‚’è©¦è¡Œã—ã¦ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’æä¾›
        
        Returns:
            float: USD to JPY conversion rate
        """
        import requests
        logger = logging.getLogger(__name__)
        
        # APIå€™è£œãƒªã‚¹ãƒˆï¼ˆå„ªå…ˆé †ä½é †ï¼‰
        apis = [
            {
                "url": "https://api.fxratesapi.com/latest?base=USD&currencies=JPY",
                "path": ["rates", "JPY"]
            },
            {
                "url": "https://api.exchangerate-api.com/v4/latest/USD",
                "path": ["rates", "JPY"]
            },
            {
                "url": "https://api.exchangerate.host/latest?base=USD&symbols=JPY",
                "path": ["rates", "JPY"]
            }
        ]
        
        for i, api in enumerate(apis):
            try:
                response = requests.get(api["url"], timeout=3)
                response.raise_for_status()
                data = response.json()
                
                # ãƒ‘ã‚¹ã«å¾“ã£ã¦ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                current_data = data
                for key in api["path"]:
                    if key in current_data:
                        current_data = current_data[key]
                    else:
                        raise ValueError(f"Key '{key}' not found in response")
                
                rate = float(current_data)
                if 100 <= rate <= 200:  # å¦¥å½“ãªç¯„å›²ãƒã‚§ãƒƒã‚¯
                    logger.info(f"Current USD-JPY rate: {rate} (from API #{i+1})")
                    return rate
                else:
                    raise ValueError(f"Rate {rate} is outside reasonable range")
                    
            except Exception as e:
                logger.debug(f"API #{i+1} failed: {e}")
                continue
        
        # ã™ã¹ã¦ã®APIãŒå¤±æ•—ã—ãŸå ´åˆ
        logger.warning(f"All exchange rate APIs failed. Using fallback rate: {cls.USD_TO_JPY_RATE}")
        return cls.USD_TO_JPY_RATE

    # ==================================================
    # MJS 45-Column CSV Headers (å®Œå…¨ä¸€è‡´)
    # ==================================================
    MJS_45_COLUMNS = [
        "ä¼ç¥¨æ—¥ä»˜", "å†…éƒ¨æœˆ", "ä¼ç¥¨NO", "è¨¼æ†‘NO", "ãƒ‡ãƒ¼ã‚¿ç¨®åˆ¥", "ä»•è¨³å…¥åŠ›å½¢å¼",
        "ï¼ˆå€Ÿï¼‰ç§‘ç›®ï½ºï½°ï¾„ï¾", "ï¼ˆå€Ÿï¼‰è£œåŠ©ï½ºï½°ï¾„ï¾", "ï¼ˆå€Ÿï¼‰éƒ¨é–€ï½ºï½°ï¾„ï¾", "ï¼ˆå€Ÿï¼‰ã‚»ã‚°ãƒ¡ãƒ³ãƒˆï½ºï½°ï¾„ï¾",
        "ï¼ˆå€Ÿï¼‰æ¶ˆè²»ç¨åŒºåˆ†", "ï¼ˆå€Ÿï¼‰æ¥­ç¨®", "ï¼ˆå€Ÿï¼‰ç¨è¾¼åŒºåˆ†", "ï¼ˆå€Ÿï¼‰è£œåŠ©åŒºåˆ†1",
        "ï¼ˆå€Ÿï¼‰è£œåŠ©ï½ºï½°ï¾„ï¾1", "ï¼ˆå€Ÿï¼‰è£œåŠ©åŒºåˆ†2", "ï¼ˆå€Ÿï¼‰è£œåŠ©ï½ºï½°ï¾„ï¾2",
        "ï¼ˆè²¸ï¼‰ç§‘ç›®ï½ºï½°ï¾„ï¾", "ï¼ˆè²¸ï¼‰è£œåŠ©ï½ºï½°ï¾„ï¾", "ï¼ˆè²¸ï¼‰éƒ¨é–€ï½ºï½°ï¾„ï¾", "ï¼ˆè²¸ï¼‰ã‚»ã‚°ãƒ¡ãƒ³ãƒˆï½ºï½°ï¾„ï¾",
        "ï¼ˆè²¸ï¼‰æ¶ˆè²»ç¨åŒºåˆ†", "ï¼ˆè²¸ï¼‰æ¥­ç¨®", "ï¼ˆè²¸ï¼‰ç¨è¾¼åŒºåˆ†", "ï¼ˆè²¸ï¼‰è£œåŠ©åŒºåˆ†1",
        "ï¼ˆè²¸ï¼‰è£œåŠ©ï½ºï½°ï¾„ï¾1", "ï¼ˆè²¸ï¼‰è£œåŠ©åŒºåˆ†2", "ï¼ˆè²¸ï¼‰è£œåŠ©ï½ºï½°ï¾„ï¾2",
        "é‡‘é¡", "æ¶ˆè²»ç¨é¡", "æ¶ˆè²»ç¨ï½ºï½°ï¾„ï¾", "æ¶ˆè²»ç¨ç‡", "å¤–ç¨åŒæ™‚å…¥åŠ›åŒºåˆ†",
        "è³‡é‡‘ç¹°å…¥åŠ›åŒºåˆ†", "è³‡é‡‘ç¹°ï½ºï½°ï¾„ï¾", "æ‘˜è¦", "æ‘˜è¦ã‚³ãƒ¼ãƒ‰1", "æ‘˜è¦ã‚³ãƒ¼ãƒ‰2",
        "æ‘˜è¦ã‚³ãƒ¼ãƒ‰3", "æ‘˜è¦ã‚³ãƒ¼ãƒ‰4", "æ‘˜è¦ã‚³ãƒ¼ãƒ‰5", "æœŸæ—¥", "ä»˜ç®‹", "ä»˜ç®‹ã‚³ãƒ¡ãƒ³ãƒˆ",
        "äº‹æ¥­è€…å–å¼•åŒºåˆ†"
    ]
    
    # 5ã‚«ãƒ©ãƒ JSONã®å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
    REQUIRED_JSON_FIELDS = ["ä¼ç¥¨æ—¥ä»˜", "å€Ÿè²¸åŒºåˆ†", "ç§‘ç›®å", "é‡‘é¡", "æ‘˜è¦"]
    
    # ==================================================
    # Target PDF File Patterns
    # ==================================================
    PDF_FILE_PATTERNS = [
        "è¥¿äº¬ï¼ˆ2æœˆï¼‰.pdf",
        "é€€å»ï¼ˆ2æœˆï¼‰.pdf", 
        "å®¶è³ƒï¼ˆ2æœˆï¼‰.pdf",
        "æ›´æ–°ï¼ˆ2æœˆï¼‰.pdf",
        "ä¸‰è±ï¼ˆ2æœˆï¼‰.pdf",
        "æŒ¯æ›¿ï¼ˆ2æœˆï¼‰.pdf", 
        "æ–°è¦ï¼ˆ2æœˆï¼‰.pdf",
        "*.pdf"  # Accept all PDF files
    ]
    
    # ==================================================
    # Methods for Configuration Validation
    # ==================================================
    
    @classmethod
    def validate_configuration(cls) -> List[str]:
        """
        Validate the configuration and return list of issues
        
        Returns:
            List of configuration issues/warnings
        """
        issues = []
        
        # API Key validation
        if not cls.USE_MOCK_DATA:
            # Check if at least one API key is configured
            config_instance = cls()
            anthropic_key = config_instance.ANTHROPIC_API_KEY
            has_anthropic = anthropic_key and anthropic_key != 'DUMMY_API_KEY'
            
            if not has_anthropic:
                issues.append("ANTHROPIC_API_KEY is required for production use")
            
            # Validate key formats
            if anthropic_key and anthropic_key != 'DUMMY_API_KEY' and not anthropic_key.startswith('sk-ant-'):
                issues.append("ANTHROPIC_API_KEY format appears invalid (should start with 'sk-ant-')")
        
        # Directory validation
        if not cls.INPUT_DIR.exists():
            issues.append(f"Input directory does not exist: {cls.INPUT_DIR}")
        
        # File size validation
        if cls.MAX_FILE_SIZE_MB <= 0:
            issues.append("MAX_FILE_SIZE_MB must be greater than 0")
        
        # Processing validation
        if cls.PAGES_PER_SPLIT <= 0:
            issues.append("PAGES_PER_SPLIT must be greater than 0")
        
        if cls.API_REQUEST_INTERVAL < 0:
            issues.append("API_REQUEST_INTERVAL cannot be negative")
        
        # Amount validation
        if cls.MIN_AMOUNT < 0:
            issues.append("MIN_AMOUNT cannot be negative")
        
        if cls.MAX_AMOUNT <= cls.MIN_AMOUNT:
            issues.append("MAX_AMOUNT must be greater than MIN_AMOUNT")
        
        return issues
    
    @classmethod
    def get_api_key_summary(cls) -> Dict[str, str]:
        """
        Get summary of API key configuration (masked for security)
        
        Returns:
            Dictionary with API key status
        """
        def mask_key(key: Optional[str]) -> str:
            if not key or key == 'DUMMY_API_KEY':
                return "Not configured"
            return f"{key[:8]}...{key[-4:]}" if len(key) > 12 else "Configured"
        
        config_instance = cls()
        return {
            'anthropic': mask_key(config_instance.ANTHROPIC_API_KEY),
            'ocr_space': mask_key(cls.OCR_SPACE_API_KEY),
            'azure': mask_key(cls.AZURE_DOCUMENT_INTELLIGENCE_KEY),
        }
    
    @classmethod
    def is_production_ready(cls) -> bool:
        """
        Check if configuration is ready for production use
        
        Returns:
            True if ready for production
        """
        if cls.USE_MOCK_DATA:
            return False
            
        # Check if at least one API key is properly configured
        config_instance = cls()
        anthropic_key = config_instance.ANTHROPIC_API_KEY
        has_anthropic = anthropic_key and anthropic_key != 'DUMMY_API_KEY'
        
        if not has_anthropic:
            return False
            
        if not cls.INPUT_DIR.exists():
            return False
            
        return len(cls.validate_configuration()) == 0
    
    @classmethod
    def setup_logging(cls) -> logging.Logger:
        """
        Setup production logging configuration
        
        Returns:
            Configured logger
        """
        # Create logger
        logger = logging.getLogger('pdf_extractor')
        logger.setLevel(getattr(logging, cls.LOG_LEVEL.upper(), logging.INFO))
        
        # Remove existing handlers
        for handler in logger.handlers[:]:
            logger.removeHandler(handler)
        
        # File handler with rotation
        from logging.handlers import RotatingFileHandler
        file_handler = RotatingFileHandler(
            cls.LOG_FILE_PATH,
            maxBytes=cls.LOG_MAX_BYTES,
            backupCount=cls.LOG_BACKUP_COUNT,
            encoding='utf-8'
        )
        file_handler.setFormatter(logging.Formatter(cls.LOG_FORMAT))
        
        # Console handler
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(logging.Formatter(cls.LOG_FORMAT))
        
        # Add handlers
        logger.addHandler(file_handler)
        logger.addHandler(console_handler)
        
        return logger

# Create global config instance
config = Config()

# Legacy compatibility - keep existing variable names
BASE_DIR = config.BASE_DIR
INPUT_DIR = config.INPUT_DIR
OUTPUT_DIR = config.OUTPUT_DIR
TEMP_DIR = config.TEMP_DIR
OUTPUT_CSV_NAME = config.OUTPUT_CSV_NAME
OUTPUT_CSV_PATH = config.OUTPUT_CSV_PATH
LOG_FILE_NAME = config.LOG_FILE_NAME
ANTHROPIC_API_KEY = lambda: config.ANTHROPIC_API_KEY
USE_MOCK_DATA = config.USE_MOCK_DATA
PAGES_PER_SPLIT = config.PAGES_PER_SPLIT
API_REQUEST_INTERVAL = config.API_REQUEST_INTERVAL
MAX_TOKENS = config.ANTHROPIC_MAX_TOKENS
MODEL_NAME = config.ANTHROPIC_MODEL
LOG_LEVEL = config.LOG_LEVEL
LOG_FORMAT = config.LOG_FORMAT
MJS_45_COLUMNS = config.MJS_45_COLUMNS
ACCOUNT_CODE_CSV_PATH = config.ACCOUNT_CODE_CSV_PATH
PDF_FILE_PATTERNS = config.PDF_FILE_PATTERNS

def validate_config() -> bool:
    """
    Validate configuration and print issues
    
    Returns:
        True if configuration is valid
    """
    issues = config.validate_configuration()
    
    if issues:
        print("âš ï¸  Configuration Issues:")
        for issue in issues:
            print(f"  - {issue}")
        return False
    
    print("âœ… Configuration validation passed")
    return True

def print_config_summary():
    """Print configuration summary"""
    print("=" * 60)
    print("ğŸ“‹ Production OCR System Configuration")
    print("=" * 60)
    
    print(f"ğŸ  Base Directory: {config.BASE_DIR}")
    print(f"ğŸ“ Input Directory: {config.INPUT_DIR}")
    print(f"ğŸ“ Output Directory: {config.OUTPUT_DIR}")
    print(f"ğŸ“„ Output File: {config.OUTPUT_CSV_NAME}")
    
    print(f"\nğŸ”§ Processing Settings:")
    print(f"  - Mock Data: {'ON' if config.USE_MOCK_DATA else 'OFF'}")
    print(f"  - Debug Mode: {'ON' if config.DEBUG_MODE else 'OFF'}")
    print(f"  - Pages per Split: {config.PAGES_PER_SPLIT}")
    print(f"  - API Interval: {config.API_REQUEST_INTERVAL}s")
    print(f"  - Max File Size: {config.MAX_FILE_SIZE_MB}MB")
    
    print(f"\nğŸ” API Configuration:")
    api_summary = config.get_api_key_summary()
    for api, status in api_summary.items():
        print(f"  - {api.title()}: {status}")
    
    print(f"\nğŸ“Š Logging:")
    print(f"  - Log Level: {config.LOG_LEVEL}")
    print(f"  - Log File: {config.LOG_FILE_PATH}")
    print(f"  - Mask API Keys: {'ON' if config.MASK_API_KEYS_IN_LOGS else 'OFF'}")
    
    print(f"\nğŸš€ Production Ready: {'YES' if Config.is_production_ready() else 'NO'}")
    print("=" * 60)

if __name__ == "__main__":
    print_config_summary()
    validate_config()